{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsussi/Cloud-variability-time-frequency/blob/master/1yrplotmypanguweather.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading, running, and analysing the PanguWeather NWP foundation model"
      ],
      "metadata": {
        "id": "dfx5eyRyPcLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note: This notebook creates some big data objects and it's easy to crash the session by exhausing the System RAM. Make sure you monitor the Resources and use the `del` command to remove big data objects as necessary**"
      ],
      "metadata": {
        "id": "PAK5G-cdKfGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is based on the code in the official PanguWeather github repo:\n",
        "\n",
        "https://github.com/198808xc/Pangu-Weather"
      ],
      "metadata": {
        "id": "qJk17PRxLOVz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQD66WAGOB1C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c09828e6-50bd-42c7-a628-14db9fea265f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1lweQlxcn9fG0zKNW8ne1Khr9ehRTI6HP\n",
            "From (redirected): https://drive.google.com/uc?id=1lweQlxcn9fG0zKNW8ne1Khr9ehRTI6HP&confirm=t&uuid=47dcdd6e-ae35-452c-865b-ad7f519c31eb\n",
            "To: /content/pangu_weather_24.onnx\n",
            "100% 1.18G/1.18G [00:26<00:00, 45.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pj8QEVNpC1FyJfUabDpV4oU3NpSe0BkD\n",
            "To: /content/input_surface.npy\n",
            "100% 16.6M/16.6M [00:00<00:00, 18.4MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1--7xEBJt79E3oixizr8oFmK_haDE77SS\n",
            "From (redirected): https://drive.google.com/uc?id=1--7xEBJt79E3oixizr8oFmK_haDE77SS&confirm=t&uuid=b7760d6e-1742-42c8-a825-aefb8f23a197\n",
            "To: /content/input_upper.npy\n",
            "100% 270M/270M [00:06<00:00, 41.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# The following works in google colab but might not work in other IDEs\n",
        "#\n",
        "# The file IDs were extracted from the google drive links provided in the\n",
        "# pangu-weather repository\n",
        "#\n",
        "# download pangu_weather_24.onnx into /content/\n",
        "!gdown 1lweQlxcn9fG0zKNW8ne1Khr9ehRTI6HP\n",
        "# download input_surface.npy into /content/\n",
        "!gdown 1pj8QEVNpC1FyJfUabDpV4oU3NpSe0BkD\n",
        "# download input_upper.npy into /content/\n",
        "!gdown 1--7xEBJt79E3oixizr8oFmK_haDE77SS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx==1.17\n",
        "#If we just run a model, we only need onnxruntime*.\n",
        "!pip install onnxruntime==1.21.1\n",
        "!pip install onnxruntime-gpu==1.21.1"
      ],
      "metadata": {
        "id": "RS1FGaPwOrnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf5a15f-affb-40ac-eae5-963858191f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx==1.17\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx==1.17) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx==1.17) (5.29.4)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n",
            "Collecting onnxruntime==1.21.1\n",
            "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime==1.21.1)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.21.1) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.21.1) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.21.1) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.21.1) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.21.1) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.21.1)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime==1.21.1) (1.3.0)\n",
            "Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.21.1\n",
            "Collecting onnxruntime-gpu==1.21.1\n",
            "  Downloading onnxruntime_gpu-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.21.1) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.21.1) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.21.1) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.21.1) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.21.1) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.21.1) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime-gpu==1.21.1) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu==1.21.1) (1.3.0)\n",
            "Downloading onnxruntime_gpu-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.8/280.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnxruntime-gpu\n",
            "Successfully installed onnxruntime-gpu-1.21.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "import onnxruntime as ort\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "a0vYGLoVQYmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## this line is included in the original panguweather example code, but I found it's\n",
        "## not actually needed...\n",
        "## The directory of your input and output data\n",
        "# model_24 = onnx.load('/content/pangu_weather_24.onnx')"
      ],
      "metadata": {
        "id": "vzGySD4rO6Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if cuda is available for onnx runtime (Confirm we are using GPU)\n",
        "device = ort.get_device()\n",
        "print(device)"
      ],
      "metadata": {
        "id": "vqWZFGDAQU_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "419ad6a5-47f1-4122-8475-e1ad3d4a3a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the behavior of onnxruntime\n",
        "options = ort.SessionOptions()\n",
        "options.enable_cpu_mem_arena=False\n",
        "options.enable_mem_pattern = False\n",
        "options.enable_mem_reuse = False\n",
        "# Increase this number for faster inference and more memory consumption\n",
        "options.intra_op_num_threads = 1\n",
        "\n",
        "\n",
        "# Initialize onnxruntime session for Pangu-Weather Models\n",
        "if device == 'GPU':\n",
        "  ort_session_24 = ort.InferenceSession('/content/pangu_weather_24.onnx',\n",
        "                                        sess_options=options,\n",
        "                                        providers=[('CUDAExecutionProvider', {'arena_extend_strategy':'kSameAsRequested',})])\n",
        "else:\n",
        "  ort_session_24 = ort.InferenceSession('/content/pangu_weather_24.onnx',\n",
        "                                        sess_options=options,\n",
        "                                        providers=['CPUExecutionProvider'])"
      ],
      "metadata": {
        "id": "BubzHoYHYHMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upper_ids = {\n",
        "'2000-01-01': '1_BriXxo6hQfIsNqkYccF7ZKmSStzprDM',\n",
        "'2000-01-02': '1hwjv48IGZwjVkssrAEtW9-edy4EjZuUk',\n",
        "'2000-01-03': '1MwzFENTAmUfVHABPEJCuiLhuGi5_vGcy',\n",
        "'2000-01-04': '1TJvqcqaZLCOjMVae_rLwiYeTj5sNTUTc',\n",
        "'2000-01-05': '1yg1kzYejBTE1nsYJ-TVYu5tj5iPY7I4m',\n",
        "'2000-01-06': '1fiRSqydIE9Tvjre1kWGgg34SANzosMnu',\n",
        "'2000-01-07': '19pdrfPzl9ylvniY3VudFXh2U0f8OohSo',\n",
        "'2000-01-08': '1Uu1JkAJkXKwCkJpn1XnDgJ0H-PaKhJ1l',\n",
        "'2000-01-09': '1nXyJ8cGAjnzMFsB7llBNrk2di03JEa47',\n",
        "'2000-01-10': '1Kfo2ZqctAUvPncQOP3x2UzRcPEgwpGIL',\n",
        "'2000-01-11': '1NOiHyoOdQ8MamIIWEPurJJyLqbKvCZP1',\n",
        "'2000-01-12': '1lmjABwyFQgXqzuJXiSGB3C6tgwHNHeEB',\n",
        "'2000-01-13': '1fRiZXeLrm7bsjfOhq9K-mF7D62otJbje',\n",
        "'2000-01-14': '1m061E8ibjvVJEK8XoXlSA0lRDtcwB47X',\n",
        "'2000-01-15': '15K_CqYbA5irwhVIXHPHbGdW9d_urKiyA',\n",
        "'2000-01-16': '1XeKMYEdH5OiF1kvrI4v49cUofKqqyO25',\n",
        "'2000-01-17': '1IAzmkxMHnICUkP3_S-LwxZrssYm6WkB8',\n",
        "'2000-01-18': '1BgCXJLz8tzgIdutraIWNdVqC5bhjSzRl',\n",
        "'2000-01-19': '1vkLgNRe4ZTDC_gjbL0cK5rFkRDqlKHP5',\n",
        "'2000-01-20': '1tB1E2oSa2g7Uh-97vnlGvqToRWa3vepG',\n",
        "'2000-01-21': '1Z8dRhLHnJr1yUWgWu_IVoug5SDHVH-7j',\n",
        "'2000-01-22': '1JVaqLRjTpL7h-mG14UNPEVxiNPqWozsl',\n",
        "'2000-01-23': '15T9AAo64GrgIWT7_jRnYcm13eEdEI7hd',\n",
        "'2000-01-24': '1VPwL69TyMG5LgzBVVzOz6GZ9bwASuh2T',\n",
        "'2000-01-25': '1E1r9T1vCVAAz9U5-KJCgtbv8-DF7vmA1',\n",
        "'2000-01-26': '1npeTU-dosRskrjS2zQz7lguFToV4cypT',\n",
        "'2000-01-27': '1G98us1MyIAMK1iZ4ZvMyL0n6ap2w_FyD',\n",
        "'2000-01-28': '1XdE03wMcR42-Rvf085vdhbsboEWD-NSc',\n",
        "'2000-01-29': '1LeaoyDJCW33GY1vkqb4AUDduqNeqTxRZ',\n",
        "'2000-01-30': '1TqZh83UxzlHwPmppHJs5MMlFHRGZCjyq',\n",
        "'2000-01-31': '1tkVM1bvTMzfXRGIBoObHt2QjHpy_yJu4'\n",
        "}\n",
        "\n",
        "surface_ids = {\n",
        "'2000-01-01': '1Wj4BJ2adcXVchWZ_C6Rkkxl5-AGRmqH2',\n",
        "'2000-01-02': '19edCDwI-EKg8I5VUPR3xtm7Kl3UxrM2J',\n",
        "'2000-01-03': '1q3tcLtKd7ZRcwUWC201nIV91ZfKQ3fAq',\n",
        "'2000-01-04': '1Gkby-FraqujedNpgz-6QENE_V54XodEI',\n",
        "'2000-01-05': '1db2F89Tsag7l4CHUjydhQMd1kquBbIde',\n",
        "'2000-01-06': '1YMJhZBdLEtnC7w2XkbFSJU5zNduO-uQm',\n",
        "'2000-01-07': '15H1YR7x5XfyNHf__NvNpvapVejguS8yz',\n",
        "'2000-01-08': '1r2tF16TRUEFCApwqxnLH670iYGFmVIX8',\n",
        "'2000-01-09': '1orVKqMyoKpcbpNh-VMW3H0DzKjzlkVRc',\n",
        "'2000-01-10': '1av3WGMy5bhrpuUwyCOddRjSuqKmhC3lR',\n",
        "'2000-01-11': '1DApynVbDWz0MHHK0-MHK0kyMUMKkQx6a',\n",
        "'2000-01-12': '1JOhvq-UMsbvMVYf8pjePnQFwmywZRe0m',\n",
        "'2000-01-13': '1XT2A3O5g2HhUpu8KQ5NcXC2_txmWTVXC',\n",
        "'2000-01-14': '16WLHCwx_y5nQWvPs6oPBU5YWv3QfcS5e',\n",
        "'2000-01-15': '1tHJt-N9EJFc7E4dSUEl-QJibx2Y1Izxt',\n",
        "'2000-01-16': '1SwxMaGOAj3YZOG3c8brrN2PJqEOwmD6c',\n",
        "'2000-01-17': '1orhxOzyjiiJkz4Jsa8emqREGXHxx0ByK',\n",
        "'2000-01-18': '1giZ_ixzKNpNQPMTYQnmo7LmbwWEn_TRT',\n",
        "'2000-01-19': '1zd13tSPr9-DomRw0AIoAy388NYh6CKZc',\n",
        "'2000-01-20': '1_44TAp8Mu21cSOSJnf02kvdGF_yvZJU4',\n",
        "'2000-01-21': '14h9Xzc8XVi5fwWopqZfbNo7whgBQxHGM',\n",
        "'2000-01-22': '1f3pAFXnpjufuX_WaDVGWKOtwGIEx7RUb',\n",
        "'2000-01-23': '14suWnpovT-hfulhvWaIy8SWUmEQyFnfo',\n",
        "'2000-01-24': '1wWngvgNXAzcfmt6ze5tftnpc8l3Tuir8',\n",
        "'2000-01-25': '12c4bKZz7JTgZVx5mjl3fl1wLH4D_SEc9',\n",
        "'2000-01-26': '1go6MKMFdAq9ojPiNQQK1fXh1EWjPRtco',\n",
        "'2000-01-27': '1HlGVittKwBJUrGsN5H-qHysGgMh4N2SX',\n",
        "'2000-01-28': '1vcNmEfI2jJCjcd0oKKcvjOOPq5nl2k47',\n",
        "'2000-01-29': '1K6oElZrsQ-5_0h32zchL9Q2tf22slsee',\n",
        "'2000-01-30': '1nfXjB2k7rqX6UThvbz637ie1XP1ig3di',\n",
        "'2000-01-31': '13Bl1B-g0uDw4drcO5RNEG9nCJX6u_CCo'\n",
        "}"
      ],
      "metadata": {
        "id": "EGVel4W7CWlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get upper and surface id for a given date and download files\n",
        "date = '2000-01-01'\n",
        "upper_id = upper_ids[date]\n",
        "surface_id = surface_ids[date]\n",
        "!gdown $upper_id\n",
        "!gdown $surface_id"
      ],
      "metadata": {
        "id": "4b8gTbzdCeVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d7f628-dd54-41d1-a7fa-5e2a3147ba2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1_BriXxo6hQfIsNqkYccF7ZKmSStzprDM\n",
            "From (redirected): https://drive.google.com/uc?id=1_BriXxo6hQfIsNqkYccF7ZKmSStzprDM&confirm=t&uuid=9cc2331d-b69a-488c-82ab-1c70dafbee0b\n",
            "To: /content/input_upper_20000101.npy\n",
            "100% 270M/270M [00:04<00:00, 58.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Wj4BJ2adcXVchWZ_C6Rkkxl5-AGRmqH2\n",
            "To: /content/input_surface_20000101.npy\n",
            "100% 16.6M/16.6M [00:00<00:00, 39.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load files into numpy arrays\n",
        "inputs_upper = np.load('/content/input_upper_20000101.npy').astype(np.float32)\n",
        "inputs_surface = np.load('/content/input_surface_20000101.npy').astype(np.float32)"
      ],
      "metadata": {
        "id": "sE4PybWL0Kqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "longitudes_list = list(np.arange(0,360,0.25))\n",
        "latitudes_list = list(np.arange(90, -90-0.25, 0.25))\n",
        "# list(arr)"
      ],
      "metadata": {
        "id": "MIb9kAcUfK6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "2Sl-d4O-m9Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For further study: One month of data\n",
        "\n",
        "Below are links to individual panguweather input data for January 2000.\n"
      ],
      "metadata": {
        "id": "i_KxaGmV0XQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_surface.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5IQMPy2cq5z",
        "outputId": "dcb2969b-0ecd-41a7-c29b-ac4837085caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 721, 1440)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_upper.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBWCyN1hV9cp",
        "outputId": "64dcc1cc-86da-4762-ebd3-cb28fbfc07a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 13, 721, 1440)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "dims = (\"time\", \"variable\", \"lat\", \"lon\")\n",
        "coords = {\n",
        "    \"time\": np.arange(180),\n",
        "    \"lat\": np.arange(-90, 90.25, 0.25),\n",
        "    \"lon\": np.arange(0, 360, 0.25),\n",
        "    \"variable\": [\"mslp\", \"u10\", \"v10\", \"t2m\"]\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "UXxYWlKmVvwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Plus4K Experiment'''\n",
        "#Example to make prediction for 30 days ahead.\n",
        "# Initialize inputs\n",
        "current_input = inputs_upper.copy()\n",
        "current_input_surface = inputs_surface.copy()\n",
        "current_input_surface[3,...] = current_input_surface[3,...]+4\n",
        "\n",
        "# Store all outputs\n",
        "outputs_p4k = []\n",
        "outputs_surface_p4k = []\n",
        "\n",
        "# Run autoregressive loop for 180 days\n",
        "for step in range(180):\n",
        "    # Run inference\n",
        "    output_upper, output_surface = ort_session_24.run(None, {\n",
        "        'input': current_input,\n",
        "        'input_surface': current_input_surface\n",
        "    })\n",
        "\n",
        "    # Plot outputs and verify for every 30 days\n",
        "    # if (step + 1) % 30 == 0:\n",
        "    #   # Verification\n",
        "    #   # download target data for verification\n",
        "      # # Plotting\n",
        "      # t2m_in = inputs_surface[3,...]\n",
        "      # t2m_out = output_surface[3,...]\n",
        "      # fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "      # axs[0].imshow(t2m_in, cmap='jet')\n",
        "      # axs[0].set_title('Input Surface T2M 1st Jan2020+4K')\n",
        "      # axs[1].imshow(t2m_out, cmap='jet')\n",
        "      # axs[1].set_title('Output Surface T2M Jan '+str(step + 1)+ ' 2020')\n",
        "      # axs[2].imshow(t2m_out - t2m_in, cmap='RdBu_r')\n",
        "      # axs[2].set_title('difference')\n",
        "      # plt.colorbar(axs[0].images[0], ax=axs[0], fraction=0.02, pad=0.05)\n",
        "      # plt.colorbar(axs[1].images[0], ax=axs[1], fraction=0.02, pad=0.05)\n",
        "      # plt.colorbar(axs[2].images[0], ax=axs[2], fraction=0.02, pad=0.05)\n",
        "      # plt.tight_layout()\n",
        "      # plt.show()\n",
        "      # if (step + 1) == 30:\n",
        "      #   date = '2000-01-30'\n",
        "      #   upper_id = upper_ids[date]\n",
        "      #   surface_id = surface_ids[date]\n",
        "      #   !gdown $upper_id\n",
        "      #   !gdown $surface_id\n",
        "      #   # load data\n",
        "      #   targets_upper = np.load('/content/input_upper_20000130.npy')\n",
        "      #   targets_surface = np.load('/content/input_surface_20000130.npy')\n",
        "      #   print('standard deviation')\n",
        "      #   std = np.std(targets_upper, axis=(1,2,3))\n",
        "      #   print(*std, sep='\\n')\n",
        "      #   print('output_upper vs targets_upper')\n",
        "      #   rms_upper_output_targets = np.mean((output_upper - targets_upper)**2, axis=(1,2,3))\n",
        "      #   print(*rms_upper_output_targets, sep='\\n')\n",
        "      #   print('normalized output_upper vs targets_upper')\n",
        "      #   #result = a / b[:, None, None, None]\n",
        "      #   print(*rms_upper_output_targets/std[:, None, None, None], sep='\\n')\n",
        "      #   # for comparison, also calculate MSE of the persistence forecast (tomorrow will be like today)\n",
        "      #   print('inputs_upper vs targets_upper')\n",
        "      #   rms_upper_input_targets = np.mean((inputs_upper - targets_upper)**2, axis=(1,2,3))\n",
        "      #   print(*rms_upper_input_targets, sep='\\n')\n",
        "      #   print('normalized input_upper vs targets_upper')\n",
        "      #   print(*rms_upper_input_targets/std[:,None, None, None], sep='\\n')\n",
        "\n",
        "    # Save outputs for plus4K\n",
        "    outputs_p4k.append(output_upper)\n",
        "    outputs_surface_p4k.append(output_surface)\n",
        "\n",
        "    # Prepare inputs for next step (autoregressive)\n",
        "    current_input = output_upper\n",
        "    current_input_surface = output_surface"
      ],
      "metadata": {
        "id": "iS5bdyDlsGXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataArray first\n",
        "outputs_surface_p4k_xr= xr.DataArray(outputs_surface_p4k, dims=dims, coords=coords)\n",
        "# Then convert to Dataset by splitting the variable dimension\n",
        "xrdataset_surface_p4k = outputs_surface_p4k_xr.to_dataset(dim=\"variable\")\n",
        "print(xrdataset_surface_p4k)"
      ],
      "metadata": {
        "id": "6qF5-l3aLTOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume 'data' has dimensions ['time', 'lat', 'lon']\n",
        "# and you want to calculate a time-averaged global mean\n",
        "import numpy as np\n",
        "weights = np.cos(np.deg2rad(xrdataset_surface['lat']))\n",
        "weights.name = \"weights\"\n",
        "\n",
        "# Broadcast weights to match dimensions\n",
        "global_mean_t2m_p4k = xrdataset_surface_p4k[\"t2m\"].weighted(weights).mean(dim=[\"lat\", \"lon\"])\n",
        "print(global_mean_t2m_p4k)"
      ],
      "metadata": {
        "id": "sD9TnlNsMXG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example to make prediction for 180 days ahead.\n",
        "# Initialize inputs\n",
        "current_input = inputs_upper.copy()\n",
        "current_input_surface = inputs_surface.copy()\n",
        "\n",
        "# Store all outputs\n",
        "outputs = []\n",
        "outputs_surface = []\n",
        "\n",
        "# Run autoregressive loop for 180 days\n",
        "for step in range(180):\n",
        "    # Run inference\n",
        "    output_upper, output_surface = ort_session_24.run(None, {\n",
        "        'input': current_input,\n",
        "        'input_surface': current_input_surface\n",
        "    })\n",
        "\n",
        "    # # Plot outputs and verify for every 30 days\n",
        "    # if (step + 1) % 30 == 0:\n",
        "    #   # Verification\n",
        "    #   # download target data for verification\n",
        "    #   # Plotting\n",
        "    #   t2m_in = inputs_surface[3,...]\n",
        "    #   t2m_out = output_surface[3,...]\n",
        "    #   fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    #   axs[0].imshow(t2m_in, cmap='jet')\n",
        "    #   axs[0].set_title('Input Surface T2M 1st Jan2020')\n",
        "    #   axs[1].imshow(t2m_out, cmap='jet')\n",
        "    #   axs[1].set_title('Output Surface T2M Jan '+str(step + 1)+ ' 2020')\n",
        "    #   axs[2].imshow(t2m_out - t2m_in, cmap='RdBu_r')\n",
        "    #   axs[2].set_title('difference')\n",
        "    #   plt.colorbar(axs[0].images[0], ax=axs[0], fraction=0.02, pad=0.05)\n",
        "    #   plt.colorbar(axs[1].images[0], ax=axs[1], fraction=0.02, pad=0.05)\n",
        "    #   plt.colorbar(axs[2].images[0], ax=axs[2], fraction=0.02, pad=0.05)\n",
        "    #   plt.tight_layout()\n",
        "    #   plt.show()\n",
        "    #   if (step + 1) == 30:\n",
        "    #     date = '2000-01-30'\n",
        "    #     upper_id = upper_ids[date]\n",
        "    #     surface_id = surface_ids[date]\n",
        "    #     !gdown $upper_id\n",
        "    #     !gdown $surface_id\n",
        "    #     # load data\n",
        "    #     targets_upper = np.load('/content/input_upper_20000130.npy')\n",
        "    #     targets_surface = np.load('/content/input_surface_20000130.npy')\n",
        "    #     print('standard deviation')\n",
        "    #     std = np.std(targets_upper, axis=(1,2,3))\n",
        "    #     print(*std, sep='\\n')\n",
        "    #     print('output_upper vs targets_upper')\n",
        "    #     rms_upper_output_targets = np.mean((output_upper - targets_upper)**2, axis=(1,2,3))\n",
        "    #     print(*rms_upper_output_targets, sep='\\n')\n",
        "    #     print('normalized output_upper vs targets_upper')\n",
        "    #     #result = a / b[:, None, None, None]\n",
        "    #     print(*rms_upper_output_targets/std[:, None, None, None], sep='\\n')\n",
        "    #     # for comparison, also calculate MSE of the persistence forecast (tomorrow will be like today)\n",
        "    #     print('inputs_upper vs targets_upper')\n",
        "    #     rms_upper_input_targets = np.mean((inputs_upper - targets_upper)**2, axis=(1,2,3))\n",
        "    #     print(*rms_upper_input_targets, sep='\\n')\n",
        "    #     print('normalized input_upper vs targets_upper')\n",
        "    #     print(*rms_upper_input_targets/std[:,None, None, None], sep='\\n')\n",
        "\n",
        "    # Save outputs\n",
        "    outputs.append(output_upper)\n",
        "    outputs_surface.append(output_surface)\n",
        "\n",
        "    # Prepare inputs for next step (autoregressive)\n",
        "    current_input = output_upper\n",
        "    current_input_surface = output_surface\n"
      ],
      "metadata": {
        "id": "1Yd_b5J32YA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJVaiBsEp_bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "dims = (\"time\", \"variable\", \"lat\", \"lon\")\n",
        "coords = {\n",
        "    \"time\": np.arange(180),\n",
        "    \"lat\": np.arange(-90, 90.25, 0.25),\n",
        "    \"lon\": np.arange(0, 360, 0.25),\n",
        "    \"variable\": [\"mslp\", \"u10\", \"v10\", \"t2m\"]\n",
        "\n",
        "}\n",
        "# Convert to DataArray first\n",
        "outputs_surface_xr= xr.DataArray(outputs_surface, dims=dims, coords=coords)\n",
        "# Then convert to Dataset by splitting the variable dimension\n",
        "xrdataset_surface = outputs_surface_xr.to_dataset(dim=\"variable\")\n",
        "print(xrdataset_surface)"
      ],
      "metadata": {
        "id": "JmeeQessVMeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume 'data' has dimensions ['time', 'lat', 'lon']\n",
        "# and you want to calculate a time-averaged global mean\n",
        "\n",
        "weights = np.cos(np.deg2rad(xrdataset_surface['lat']))\n",
        "weights.name = \"weights\"\n",
        "\n",
        "# Broadcast weights to match dimensions\n",
        "global_mean_t2m = xrdataset_surface[\"t2m\"].weighted(weights).mean(dim=[\"lat\", \"lon\"])\n",
        "print(global_mean_t2m)"
      ],
      "metadata": {
        "id": "nOXKhbz_qjo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(global_mean_t2m)\n",
        "plt.plot(global_mean_t2m_p4k)"
      ],
      "metadata": {
        "id": "TWqfmgK2M1OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MSE comparison\n",
        "\n",
        "Below is example code to download ERA5 data for one date, make a one-day ahead prediction with panguweather_24 and compare the output to ERA5 data for the following day."
      ],
      "metadata": {
        "id": "eZEosfK4Du9k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A8FO1vNeDt_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make pangu weather prediction\n",
        "outputs_upper, outputs_surface = ort_session_24.run(None, {'input':inputs_upper, 'input_surface':inputs_surface})"
      ],
      "metadata": {
        "id": "MGrQmvv2DYRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download target data for verification\n",
        "date = '2000-01-30'\n",
        "upper_id = upper_ids[date]\n",
        "surface_id = surface_ids[date]\n",
        "!gdown $upper_id\n",
        "!gdown $surface_id"
      ],
      "metadata": {
        "id": "nodd46vw1PSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets_upper = np.load('/content/input_upper_20000130.npy')\n",
        "targets_surface = np.load('/content/input_surface_20000130.npy')"
      ],
      "metadata": {
        "id": "qkD7Ej9m1fHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(*np.mean((outputs_upper - targets_upper)**2, axis=(1,2,3)), sep='\\n')"
      ],
      "metadata": {
        "id": "DlnaINQuEQHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for comparison, also calculate MSE of the persistence forecast (tomorrow will be like today)\n",
        "print(*np.mean((inputs_upper - targets_upper)**2, axis=(1,2,3)), sep='\\n')"
      ],
      "metadata": {
        "id": "kMg02bGYEe-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# persistence mse is significantly higher than pangu weather mse\n",
        "# roughly by a factor 10, indicating skillful predictions from\n",
        "# panguweather that comfortably outperform the no-change forecast"
      ],
      "metadata": {
        "id": "jQSlELiCE4bT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9En7z63SK_Qr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}