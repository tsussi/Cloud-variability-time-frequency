{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsussi/Cloud-variability-time-frequency/blob/master/03_tensorflow_torch_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1849578-f4aa-4a0c-94f8-ea9876bdba59",
      "metadata": {
        "id": "d1849578-f4aa-4a0c-94f8-ea9876bdba59"
      },
      "source": [
        "# 3.1 Introduction to TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58bb43d8-e333-4814-9546-0b24d939fd00",
      "metadata": {
        "id": "58bb43d8-e333-4814-9546-0b24d939fd00"
      },
      "source": [
        "**TensorFlow** is an open-source software library for machine learning and artificial intelligence developed by Google. It can be used across a range of tasks such as image recognition and natural language processing, but it is used mainly for training and inference of neural networks.\n",
        "\n",
        "Some useful links and materials:\n",
        "- [TensorFlow Homepage](https://www.tensorflow.org/)\n",
        "- [TensorFlow Github](https://github.com/tensorflow/tensorflow)\n",
        "- [TensorFlow Forum](https://www.tensorflow.org/community)\n",
        "\n",
        "TensorFlow supports both low-level operations (for flexibility and custom models) and high-level APIs (Application Programming Interface) (like Keras). In this session, we will mainly focus on the low-level frameworks and operations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62e463ba-e948-478e-8de3-78e68ac2ae5d",
      "metadata": {
        "id": "62e463ba-e948-478e-8de3-78e68ac2ae5d"
      },
      "source": [
        "Learning to use the lower-level frameworks in TensorFlow and PyTorch allows us to do the following:\n",
        "\n",
        "- **Custom training loops:** more control over the training process, which can be useful for non-standard training procedures\n",
        "- **Custom model:** flexibility in defining deep learning models with trainable parameters\n",
        "- **Lower-level tensor operations:** fine control over tensor manipulations, e.g., custom attention layers\n",
        "- **Custom loss functions:** you can define custom loss functions and evaluation metrics (this is useful for physics-informed neural networks)\n",
        "- **Distributed training:** control over multi-GPU/TPU training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be2f4ccc-4653-42b1-8272-133a2d0e95f6",
      "metadata": {
        "id": "be2f4ccc-4653-42b1-8272-133a2d0e95f6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# load additional Python libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# import relevant keras libraries\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25c5c185-e02d-440e-a251-2a7ff9509fb2",
      "metadata": {
        "id": "25c5c185-e02d-440e-a251-2a7ff9509fb2"
      },
      "source": [
        "## TensorFlow Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13203f03-e43c-4c1d-a1c5-49623c275fcf",
      "metadata": {
        "id": "13203f03-e43c-4c1d-a1c5-49623c275fcf"
      },
      "source": [
        "In TensorFlow, we use **tensors**, which are multi-dimensional arrays with a uniform type (`dtype`). Tensors are quiet similar to `np.arrays` in NumPy. In addition, all tensors are immutable like Python numbers and strings (you can never update the contents of tensor, only create a new one) except `tf.Variable`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b166cbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "3b166cbc",
        "outputId": "cc40c8ed-9f68-4829-8192-e3bd61fcd960"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1c2c6840f9e7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m37\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_enable_numpy_behavior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m       \"\"\")\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'"
          ]
        }
      ],
      "source": [
        "x = tf.constant([12, 2, 37, 100])\n",
        "x[0].assign(99)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb791d6b-14d2-40cf-b5d0-894b55310f94",
      "metadata": {
        "id": "eb791d6b-14d2-40cf-b5d0-894b55310f94"
      },
      "source": [
        "## Basic linear algebra example in Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b8007aa-83f6-4cc8-a659-8059cca8b3fe",
      "metadata": {
        "id": "8b8007aa-83f6-4cc8-a659-8059cca8b3fe"
      },
      "source": [
        "We can perform a matrix multiplication with TensorFlow using a code below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6165586d-7f43-4107-b365-cb466de7fdfe",
      "metadata": {
        "id": "6165586d-7f43-4107-b365-cb466de7fdfe"
      },
      "source": [
        "## Linear regression in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d626a100-ff1c-4b2c-ae52-2fbcf5d169ec",
      "metadata": {
        "id": "d626a100-ff1c-4b2c-ae52-2fbcf5d169ec"
      },
      "source": [
        "To understand a standard workflow in TensorFlow and it is different to Keras, let's consider a simple linear model problem. We start by generating a simple data set with a single input parameter $x$ and output (response) $y$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f96e4546-486e-4610-8420-8c6e655af14c",
      "metadata": {
        "id": "f96e4546-486e-4610-8420-8c6e655af14c",
        "outputId": "0c2f8ecd-14da-4de4-aca8-f5e47d54305b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix A:\n",
            " [[1. 2.]\n",
            " [3. 4.]]\n",
            "Matrix B:\n",
            " [[5. 6.]\n",
            " [7. 8.]]\n",
            "A * B:\n",
            " [[19. 22.]\n",
            " [43. 50.]]\n",
            "A - B:\n",
            " [[-4. -4.]\n",
            " [-4. -4.]]\n"
          ]
        }
      ],
      "source": [
        "# Define two 2 by 2 constant matrices with tf.constant\n",
        "A = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
        "B = tf.constant([[5, 6], [7, 8]], dtype=tf.float32)\n",
        "\n",
        "# Multiply the matrices\n",
        "C = tf.matmul(A, B)\n",
        "\n",
        "# Subtract the matrices\n",
        "D = tf.subtract(A, B)\n",
        "\n",
        "# Run the computation\n",
        "print(\"Matrix A:\\n\", A.numpy())\n",
        "print(\"Matrix B:\\n\", B.numpy())\n",
        "print(\"A * B:\\n\", C.numpy())\n",
        "print(\"A - B:\\n\", D.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c2a8b1e-b3f0-42fd-bc89-6de5b17a0c53",
      "metadata": {
        "id": "8c2a8b1e-b3f0-42fd-bc89-6de5b17a0c53"
      },
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(1234)\n",
        "\n",
        "# Generate synthetic data\n",
        "X_np = np.linspace(0, 10, 10)\n",
        "y_np = 2 + 0.5*X_np + np.random.normal(0, 0.25, 10)\n",
        "\n",
        "# Create a constant tensor\n",
        "X = tf.constant(X_np.reshape(10, 1), dtype=tf.float32)\n",
        "y = tf.constant(y_np.reshape(10, 1), dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f81c2c9",
      "metadata": {
        "id": "1f81c2c9"
      },
      "source": [
        "We use `matplotlib` library in Python to visualise the relationship between $x$ and $y$ below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad1820b6-4ff3-4c66-9c25-48581009a610",
      "metadata": {
        "id": "ad1820b6-4ff3-4c66-9c25-48581009a610",
        "outputId": "72f99de4-37b7-431b-c7d4-b132420aa71a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot synthetic data\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.scatter(X_np, y_np, color='blue')\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.savefig(\"fig/plotlm1.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcd01f2a-7add-4b7c-beba-7874e4fb4565",
      "metadata": {
        "id": "fcd01f2a-7add-4b7c-beba-7874e4fb4565"
      },
      "source": [
        "Before we consider a standard workflow in TensorFlow, let's briefly remind ourselves how to implement a linear model in Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e876cfc9-1193-43a8-9799-dd949cb59883",
      "metadata": {
        "id": "e876cfc9-1193-43a8-9799-dd949cb59883"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "# specify a linear model with keras\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(1, input_shape=(1,), activation='linear')\n",
        "])\n",
        "# Configure the model with SGD optimizer\n",
        "optimizer = SGD(learning_rate=0.01)\n",
        "model.compile(optimizer=optimizer, loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb94143-b248-4783-9ca8-dcafdb430100",
      "metadata": {
        "id": "2eb94143-b248-4783-9ca8-dcafdb430100",
        "outputId": "9c0b1a32-8c8e-45d4-fe33-b1abc4cfb239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 1.7327\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3800\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3385\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3219\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3075\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2933\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2794\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2656\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2520\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2385\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2252\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2120\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1990\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1861\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1733\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1608\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1483\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1360\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1238\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1118\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0999\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0881\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0765\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0650\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0537\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0424\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0313\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0203\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0095\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9987\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9881\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9776\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9672\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9570\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9468\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9368\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9269\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9171\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9074\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8978\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8883\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8790\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8697\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8606\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8515\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8426\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8337\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8250\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8163\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8078\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7993\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7910\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7827\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7745\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7664\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7585\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7506\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7428\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7350\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7274\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7199\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7124\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7050\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6977\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6905\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6834\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6763\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6694\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6625\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6557\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6490\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6423\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6357\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6292\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6228\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6164\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6101\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6039\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5978\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5917\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5857\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5797\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5739\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5680\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5623\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5566\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5510\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5455\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5400\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5346\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5292\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5239\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5186\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5135\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5083\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5033\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4983\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4933\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4884\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4836\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4788\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4741\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4694\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4648\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4602\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4557\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4512\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4468\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4424\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4381\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4338\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4296\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4254\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4213\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4172\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4132\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4092\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4052\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4013\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3975\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3937\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3899\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3862\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3825\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3789\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3753\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3717\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3682\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3647\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3613\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3579\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3545\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3512\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3479\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3446\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3414\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3382\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3351\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3320\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3289\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3259\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3229\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3199\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3170\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3141\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3112\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3084\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3056\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3028\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3001\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2974\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2947\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2920\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2894\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2868\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2843\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2817\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2792\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2768\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2743\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2719\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2695\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2671\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2648\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2625\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2602\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2579\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2557\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2535\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2513\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2492\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2470\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2449\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2428\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2408\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2387\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2367\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2347\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2328\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2308\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2289\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2270\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2251\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2232\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2214\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2196\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2178\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2160\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2142\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2125\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2108\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2091\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2074\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2058\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2041\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2025\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2009\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1993\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1977\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1962\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1946\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1931\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1916\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1901\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1887\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1872\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1858\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1844\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1830\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1816\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1802\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1789\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1775\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1762\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1749\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1736\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1723\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1711\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1698\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1686\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1674\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1662\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1650\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1638\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1626\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1615\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1603\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1592\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1581\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1570\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1559\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1548\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1537\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1527\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1516\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1506\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1496\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1486\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1476\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1466\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1456\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1447\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1437\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1428\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1419\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1409\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1400\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1391\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1382\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1374\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1365\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1356\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1348\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1339\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1331\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1323\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1315\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1307\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1299\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1291\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1283\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1276\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1268\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1261\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1253\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1246\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1239\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1232\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1224\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1217\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1211\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1204\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1197\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1190\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1184\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1177\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1171\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1164\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1158\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1152\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1146\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1139\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1133\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1127\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1122\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1116\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1110\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1104\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1099\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1093\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1088\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1082\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1077\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1071\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1066\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1061\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1056\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1051\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1046\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1041\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1036\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1031\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1026\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1021\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1017\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1012\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1007\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1003\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0998\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0994\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0990\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0985\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0981\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0977\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0973\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0968\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0964\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0960\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0956\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0952\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0948\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0945\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0941\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0937\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0933\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0929\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0926\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0922\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0919\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0915\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0912\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0908\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0905\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0901\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0898\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0895\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0891\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0888\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0885\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0882\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0879\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0876\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0873\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0870\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0867\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0864\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0861\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0858\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0855\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0852\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0849\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0847\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0844\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0841\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0839\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0836\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0833\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0831\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0828\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0826\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0823\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0821\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0818\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0816\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0814\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0811\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0809\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0807\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0804\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0802\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0800\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0798\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0796\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0794\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0791\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0789\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0787\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0785\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0783\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0781\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0779\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0777\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0775\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0773\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0771\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0770\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0768\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0766\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0764\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0762\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0761\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0759\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0757\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0755\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0754\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0752\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0750\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0749\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0747\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0746\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0744\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0742\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0741\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0739\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0738\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0736\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0735\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0733\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0732\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0731\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0729\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0728\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0726\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0725\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0724\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0722\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0721\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0720\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0719\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0717\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0716\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0715\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0714\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0712\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0711\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0710\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0709\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0708\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0706\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0705\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0704\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0703\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0702\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0701\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0700\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0699\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0698\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0697\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0696\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0695\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0694\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0693\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0692\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0691\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0690\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0689\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0688\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0687\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0686\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0685\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0684\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0683\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0683\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0682\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0681\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0680\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0679\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0678\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0678\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0677\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0676\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0675\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0674\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0674\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0673\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0672\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0671\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0671\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0670\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0669\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0668\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0668\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0667\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0666\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0666\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0665\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0664\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0664\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0663\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0662\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0662\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0661\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0661\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0660\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0659\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0659\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0658\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0658\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0657\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0656\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0656\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0655\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0655\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0654\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0654\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0653\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0653\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0652\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0652\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0651\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0651\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0650\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0650\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0649\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0649\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0648\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0648\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0647\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0647\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0646\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0646\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0645\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0645\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0644\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0644\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0644\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0643\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0643\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0642\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0642\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0642\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0641\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0641\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0640\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0640\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0640\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0639\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0639\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0638\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0638\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0638\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0637\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0637\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0637\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0636\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0636\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0636\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0635\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0635\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0635\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0634\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0634\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0634\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0633\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0633\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0633\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0633\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0632\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0632\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0632\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0631\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0631\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0631\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0631\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0630\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0630\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0630\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0629\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0629\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0629\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0629\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0628\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0628\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0628\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0628\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0627\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0627\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0627\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0627\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0627\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0626\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0626\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0626\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0626\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0625\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0625\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0625\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0625\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0625\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0624\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0624\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0624\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0624\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0624\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0623\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0623\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0623\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0623\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0623\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0622\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0622\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0622\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0622\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0622\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0622\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0621\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0621\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0621\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0621\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0621\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0621\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0620\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0620\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0620\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0620\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0620\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0620\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0619\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0619\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0619\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0619\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0619\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0619\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0619\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0618\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0618\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0618\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0618\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0618\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0618\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0618\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0618\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0617\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0617\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0617\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0617\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0617\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0617\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0617\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0617\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0616\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0616\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0616\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0616\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0616\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0616\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0616\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0616\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0616\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0615\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0615\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0615\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0615\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0615\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0615\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0615\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0615\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0615\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0615\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0615\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0614\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0614\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0614\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0614\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0614\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0614\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0614\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0614\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0614\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0614\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0614\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0612\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0611\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0611\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0610\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0610\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0610\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0610\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0609\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0609\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0609\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0608\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0608\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0608\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0608\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0608\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0608\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0608\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0608\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0608\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0607\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0607\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0607\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0607\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0607\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0607\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0607\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0607\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0607\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0607\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0607\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0607\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0607\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0607\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0607\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0607\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0607\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0607\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0607\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0607\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0607\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0607\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0607\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x18764a4f0>"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_np, y_np, epochs=1000, batch_size=10) # we want to use our whole dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cc2f631",
      "metadata": {
        "id": "9cc2f631"
      },
      "source": [
        "Note that `model.compile` and `model.fit` functions handle the loss function specification and training loop for us. To ``access'' how well our linear model in keras performs, we can visualise the predictions produce by this model together with the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d221caf-1a41-4acf-9cf0-10649ef0cbea",
      "metadata": {
        "id": "7d221caf-1a41-4acf-9cf0-10649ef0cbea",
        "outputId": "0a6a0bf5-a881-40cc-c15c-2f9b65f8c9f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 39ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# produce predictions\n",
        "y_pred = model.predict(X_np)\n",
        "# plot\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.plot(X_np,y_pred, color='red', label = \"Predictions\")\n",
        "plt.scatter(X_np, y_np, color='blue', label = \"Training data\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3853bb40",
      "metadata": {
        "id": "3853bb40"
      },
      "source": [
        "In contrast to keras, TensorFlow allows us to to define **custom training loops** and **custom loss functions**. These features are highly useful for the implementation of physics-informed machine learning approaches.\n",
        "\n",
        "In TensorFlow, we start by specifing trainable variables (model parameters). Note that the `Variable()` constructor requires an initial value for the variable, which can be a `Tensor` of any type and shape which determines the type and shape of the variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d56a08b-6903-46d3-87cc-112ebab7165b",
      "metadata": {
        "id": "0d56a08b-6903-46d3-87cc-112ebab7165b"
      },
      "outputs": [],
      "source": [
        "# trainable variables with tf.Variable\n",
        "W = tf.Variable(tf.random.normal([1, 1]), dtype=tf.float32)\n",
        "b = tf.Variable(tf.zeros([1]), dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3edc1b07",
      "metadata": {
        "id": "3edc1b07"
      },
      "source": [
        "In TensorFlow, we can provide our own model specification as well as the loss function. With `linear_regression` function, we consider a linear model of the form:\n",
        "$$\n",
        "\\hat{\\mathbb{y}} = \\mathbb{\\mathrm{X}}\\mathbb{\\mathrm{W}} + b\\mathbb{1},\n",
        "$$\n",
        "where:\n",
        "- $\\mathbb{\\mathrm{X}}$ is a matrix of input features with dimensions (shapes) $[\\text{n\\_samples}, \\text{n\\_features}]$\n",
        "- $\\mathbb{\\mathrm{W}}$ is a vector of weights (coefficients) with dimensions $[\\text{n\\_features}, 1]$\n",
        "- $b$ is a bias term and $\\mathbb{1}=(1, 1, \\dots, 1)^T$\n",
        "\n",
        "We also specify a loss function with function `loss_fn`. As before with keras, we chose a **mean squared error (MSE) loss** function:\n",
        "$$\n",
        "l(\\mathbb{y}, \\hat{\\mathbb{y}}) = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{y}_i)^2.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db4e8c36-d4d2-40c7-b254-d344e26ad543",
      "metadata": {
        "id": "db4e8c36-d4d2-40c7-b254-d344e26ad543"
      },
      "outputs": [],
      "source": [
        "# linear regression model function\n",
        "def linear_regression(X): return tf.matmul(X, W) + b\n",
        "# mse loss function\n",
        "def loss_fn(y_true , y_pred):\n",
        "    return tf.reduce_mean(tf.square(y_true - y_pred)) # `reduce_mean` computes the mean of elements across dimensions of a tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4feedcb6",
      "metadata": {
        "id": "4feedcb6"
      },
      "source": [
        "To learn model parameters, it is common to use **backpropagation** which is an algorithm for training neural networks that computes gradients of a loss function with respect to model parameters (weights and biases). TensorFlow provides **autodiff framework** that uses a computational graph and backpropagation logic to calculate these gradients.\n",
        "\n",
        "In particular, we use `tf.GradientTape` which is API for automatic differentiation in TensorFlow:\n",
        "\n",
        "1. TensorFlow records every operation that involves `tf.Variable` inside the tape\n",
        "2. TensorFlow then calculates the gradients using those recorded operations with `tape.gradient`\n",
        "3. TensorFlow can then use these gradients to tell us how to update model parameters to improve model performance using `optimizer.apply_gradient`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d5465be-804b-4e44-8c45-dd1e5144e1c1",
      "metadata": {
        "id": "6d5465be-804b-4e44-8c45-dd1e5144e1c1"
      },
      "outputs": [],
      "source": [
        "# initialise optimiser\n",
        "optim = tf.optimizers.SGD(learning_rate=0.01) # gradient descent optimiser\n",
        "# training loop\n",
        "for epoch in range(1000):\n",
        "    with tf.GradientTape() as tape: # `GradientTape` records operation for automatic differentiation\n",
        "        predictions = linear_regression(X)\n",
        "        loss = loss_fn(y, predictions)\n",
        "    gradients = tape.gradient(loss, [W, b])\n",
        "    optim.apply_gradients(zip(gradients , [W, b]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa3d8c39",
      "metadata": {
        "id": "aa3d8c39"
      },
      "source": [
        "Let's visualise the predictions produced by our linear model to access how well it performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d0b1760-e6cb-4aa3-a697-c4f1b65c14b7",
      "metadata": {
        "id": "7d0b1760-e6cb-4aa3-a697-c4f1b65c14b7",
        "outputId": "9135ad89-2edc-4cd5-a277-2d6dc533b3b4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# produce and plot predictions\n",
        "predictions_np = linear_regression(X).numpy().flatten()\n",
        "# Plot\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.plot(X_np, predictions_np, color='red', label = \"Predictions\")\n",
        "plt.scatter(X_np, y_np, color='blue', label = \"Training data\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.savefig(\"fig/lm_model_pred.png\", dpi=300, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "233a20e5",
      "metadata": {
        "id": "233a20e5"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac663e75",
      "metadata": {
        "id": "ac663e75"
      },
      "source": [
        "### 3.1 (a)\n",
        "\n",
        "Consider a function $y = sin(2x) + 0.5x^2$ defined for $x\\in [-1, 2]$. Using `tf.GradientTape`, write a code to compute the $\\frac{dy}{dx}$ (please see this [link](https://www.tensorflow.org/guide/autodiff) for hints)\n",
        "\n",
        "### 3.1 (b)\n",
        "\n",
        "Using `matplotlib`, plot the following:\n",
        "\n",
        "- original function $y(x)$\n",
        "- its gradient $\\frac{dy}{dx}$ computed using TensorFlow (obtained in part 3.1 (a))\n",
        "- the analytical expression of the derivative $\\frac{dy}{dx} = 2\\cos(2x) + x$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "DSYzCeaFF3kc"
      },
      "id": "DSYzCeaFF3kc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(3.0)\n",
        "print(x)\n",
        "with tf.GradientTape() as tape:\n",
        "  y = x**2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P6k_VqAGucx",
        "outputId": "1536a0cc-8315-48fe-e380-e8710fe11f0f"
      },
      "id": "3P6k_VqAGucx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dy = 2x * dx\n",
        "dy_dx = tape.gradient(y, x)\n",
        "dy_dx.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD7aXanLG8rX",
        "outputId": "3d9b3ebd-5a31-42cb-f79b-a0e286c907e0"
      },
      "id": "OD7aXanLG8rX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(6.0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c7c2091",
      "metadata": {
        "id": "1c7c2091"
      },
      "source": [
        "# 3.2 Introduction to PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2911b546",
      "metadata": {
        "id": "2911b546"
      },
      "source": [
        "**PyTorch** is an open-source software library for machine learning and artificial intelligence developed by Meta AI. Similar to TensorFlow, it is widely used for building and training neural networks.\n",
        "\n",
        "Some useful links and materials:\n",
        "\n",
        "- [PyTorch Homepage](https://pytorch.org)\n",
        "- [PyTorch Github](https://github.com/pytorch/pytorch)\n",
        "- [PyTorch Forum](https://discuss.pytorch.org)\n",
        "\n",
        "Note that PyTorch supports both low-level operations and high-level APIs such as `torch.nn` and `torchvision`. In this session, we will mainly focus on the low-level framework and operations. We begin by importing PyTorch library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ee2f429",
      "metadata": {
        "id": "4ee2f429"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0027aab",
      "metadata": {
        "id": "e0027aab"
      },
      "source": [
        "## PyTorch Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f16a65b",
      "metadata": {
        "id": "0f16a65b"
      },
      "source": [
        "Similar to TensorFlow, all of data including inputs, outputs and trainable variables (model parameters) are expressed as **tensors**. We can use `torch.tensor` to create a new tensor object. All elements within a tensor must be of the same data type. In PyTorch, tensors are mutable objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e393bfd",
      "metadata": {
        "id": "3e393bfd",
        "outputId": "9e7f33d2-b0b3-4eb1-c8ae-3e3d4c9509e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 15,   2,  37, 100])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([12, 2, 37, 100])\n",
        "x[0] = 15\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ae999be",
      "metadata": {
        "id": "3ae999be"
      },
      "source": [
        "## Basic linear algebra example in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce003e49",
      "metadata": {
        "id": "ce003e49"
      },
      "source": [
        "We can perform basic linear algebra operations with tensors in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be9a0acf",
      "metadata": {
        "id": "be9a0acf",
        "outputId": "4f87a49d-3c8f-43dd-bcf2-634e49f33dbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix A:\n",
            " [[1. 2.]\n",
            " [3. 4.]]\n",
            "Matrix B:\n",
            " [[5. 6.]\n",
            " [7. 8.]]\n",
            "A * B:\n",
            " [[19. 22.]\n",
            " [43. 50.]]\n",
            "A - B:\n",
            " [[-4. -4.]\n",
            " [-4. -4.]]\n"
          ]
        }
      ],
      "source": [
        "# Define two 2 by 2 constant matrices with torch.tensor\n",
        "A = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "B = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
        "\n",
        "# Multiply the matrices\n",
        "C = torch.matmul(A, B)\n",
        "\n",
        "# Subtract the matrices\n",
        "D = A - B\n",
        "\n",
        "# Run the computation\n",
        "print(\"Matrix A:\\n\", A.numpy())\n",
        "print(\"Matrix B:\\n\", B.numpy())\n",
        "print(\"A * B:\\n\", C.numpy())\n",
        "print(\"A - B:\\n\", D.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edd03124",
      "metadata": {
        "id": "edd03124"
      },
      "source": [
        "## Linear regression in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bbebf06",
      "metadata": {
        "id": "3bbebf06"
      },
      "source": [
        "We return back to our simple linear regression example from *Section 3.1 Introduction to TensorFlow*. Note that when we create parameters $\\mathbb{\\mathrm{W}}$ and $b$, we specify `requires_grad=True`, which tells PyTorch to track all operations involving this tensor, so it can compute gradients later using backpropagation and is essential for automatic differentiation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c3295ef",
      "metadata": {
        "id": "1c3295ef"
      },
      "outputs": [],
      "source": [
        "# synthetic data with torch.tensor\n",
        "# convert a NumPy array to PyTorch tensor and create an independent copy\n",
        "X = torch.from_numpy(X_np).clone()\n",
        "y = torch.from_numpy(y_np).clone()\n",
        "# parameters with gradient evaluation\n",
        "W = torch.randn(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a39e7fc1",
      "metadata": {
        "id": "a39e7fc1"
      },
      "source": [
        "We then proceed to specify a linear regression model and define a loss function. The workflow in PyTorch is very similar to the one in TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3147052b",
      "metadata": {
        "id": "3147052b"
      },
      "outputs": [],
      "source": [
        "# linear model\n",
        "def linear_regression(X):\n",
        "    return X * W + b\n",
        "# Define loss function (Mean Squared Error)\n",
        "def loss_fn(y_true , y_pred):\n",
        "    return torch.mean((y_true - y_pred) ** 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ece3de3",
      "metadata": {
        "id": "9ece3de3"
      },
      "source": [
        "To learn model parameters, we will use backpropagation in PyTorch. **Automatic differentiation** (autodiff) in PyTorch automatically computes gradients (derivatives) of tensors during model training and it is therefore crucial for backpropagation. In particular, PyTorch uses a **dynamic computational graph** and tracks all operations performed on tensors with `required_grad=True`. During each iterations of the training loop, we perform the following operations:\n",
        "\n",
        "1. Clear old gradients with `optimizer.zero_grad()`\n",
        "2. Compute ML model predictions and loss\n",
        "3. Backpropagate to get gradients with `loss.backward()`\n",
        "4. Update weights to reduce the loss with `optimizer.step()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f4176ed",
      "metadata": {
        "id": "8f4176ed"
      },
      "outputs": [],
      "source": [
        "# Define optimizer\n",
        "optimizer = torch.optim.SGD([W, b], lr=0.01)\n",
        "# Training loop\n",
        "for step in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    predictions = linear_regression(X)\n",
        "    loss = loss_fn(y, predictions)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33f3d15b",
      "metadata": {
        "id": "33f3d15b"
      },
      "source": [
        "We can produce predictions of this linear model in PyTorch and visualise these predictions against training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "633cd85d",
      "metadata": {
        "id": "633cd85d",
        "outputId": "066a7eee-e9d4-474b-e6d2-4c32889693f3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# produce predictions:\n",
        "predictions.np = predictions.detach().numpy()\n",
        "# Plot\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.plot(X_np, predictions.np, color='red', label = \"Predictions\")\n",
        "plt.scatter(X_np, y_np, color='blue', label = \"Training data\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer\n",
        "optimizer = torch.optim.SGD([W, b], lr=0.01)\n",
        "# Training loop\n",
        "for step in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    y1 = x**2+3x\n",
        "    y2 = sin(y1)\n",
        "    loss = loss_fn(y2, predictions)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "gze9at-9N-78"
      },
      "id": "gze9at-9N-78",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "723e582e",
      "metadata": {
        "id": "723e582e"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "### 3.2 (a)\n",
        "\n",
        "In PyTorch using `tensor.backward`, compute the derivative with respect to $x$ of\n",
        "$$\n",
        "y_2 = \\sin(y_1), \\text{ where }y_1=x^2+3x,\n",
        "$$\n",
        "for $x\\in [-1, 2]$.\n",
        "\n",
        "### 3.2 (b)\n",
        "\n",
        "Using `matplotlib`, plot the following:\n",
        "\n",
        "- original function $y_2(x)$\n",
        "- its gradient $\\frac{dy_2}{dx}$ computed using PyTorch (obtained in part 3.2 (a))\n",
        "- the analytical expression of the derivative $\\frac{dy_2}{dx} = \\cos(x^2 + 3x)\\times (2x+3)$\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf-arm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}